{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics over Time (ToT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author information\n",
    "\n",
    "- **Name:** Jaeseong Choe\n",
    "\n",
    "- **email address:** cjssoote@gmail.com\n",
    "\n",
    "- **GitHub:** https://github.com/sorrychoe\n",
    "\n",
    "- **Linkedin:** https://www.linkedin.com/in/jaeseong-choe-048639250/\n",
    "\n",
    "- **Personal Webpage:** https://jaeseongchoe.vercel.app/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Brief background of methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "- **Topics over Time (ToT) is an extension of LDA that incorporates time as an additional observed variable, modeling how the relevance of topics changes over time.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Situation Before ToT\n",
    "\n",
    "- While LDA can model topics, they do not explicitly model the relationship between the occurrence of topics and time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why ToT Was Introduced\n",
    "\n",
    "- ToT was introduced from the paper \"Topics over Time: A Non-Markov Continuous-Time Model of Topical\n",
    "Trends.\" of Wang, X., & McCallum, A. (2006).\n",
    "\n",
    "- ToT adds time as an observed variable and models the dependency between topic relevance and time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Cases\n",
    "\n",
    "- ToT can be used in studying historical trends, such as tracking the popularity of certain subjects over decades."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Key concept of methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Concept\n",
    "\n",
    "- ToT adds time as an observed variable and incorporates it into the generative process of topic modeling.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Process\n",
    "\n",
    "ToT generates both the words and timestamps for each document, modeling time as a continuous variable. The generative process is:\n",
    "\n",
    "1. **Topic Distribution for Document**:\n",
    "   - For each document $d$, draw a topic distribution $\\theta_d$ from a Dirichlet:\n",
    "   $$\n",
    "   \\theta_d | \\alpha \\sim \\text{Dirichlet}(\\alpha)\n",
    "   $$\n",
    "\n",
    "2. **Topic-Specific Word Generation**:\n",
    "   - For each word $w_{di}$ in document $d$:\n",
    "     - Draw a topic $z_{di}$ from $\\theta_d$:\n",
    "     $$\n",
    "     z_{di} | \\theta_d \\sim \\text{Multinomial}(\\theta_d)\n",
    "     $$\n",
    "     - Draw a word $w_{di}$ from the topic-specific distribution $\\phi_{z_{di}}$:\n",
    "     $$\n",
    "     w_{di} | z_{di}, \\phi \\sim \\text{Multinomial}(\\phi_{z_{di}})\n",
    "     $$\n",
    "\n",
    "3. **Topic-Specific Timestamp Generation**:\n",
    "   - Draw a timestamp $t_{di}$ for the word from the topic's Beta distribution:\n",
    "   $$\n",
    "   t_{di} | z_{di}, \\psi \\sim \\text{Beta}(\\psi_{z_{di}})\n",
    "   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ToT_Graphic](./img/ToT_Graphic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical Representation\n",
    "\n",
    "- **Word Distribution**: \n",
    "  Each word is generated from a multinomial distribution parameterized by $\\phi_z$ for topic $z$:\n",
    "  $$\n",
    "  p(w | z, \\phi_z) = \\prod_{i=1}^V \\phi_{zi}^{w_i}\n",
    "  $$\n",
    "  where $\\phi_z$ is the multinomial distribution over words for topic $z$.\n",
    "\n",
    "- **Timestamp Distribution**:\n",
    "  The timestamp is modeled using a Beta distribution for each topic:\n",
    "  $$\n",
    "  p(t | z, \\psi_z) = \\frac{t^{\\psi_{z1} - 1} (1 - t)^{\\psi_{z2} - 1}}{B(\\psi_{z1}, \\psi_{z2})}\n",
    "  $$\n",
    "  where $B(\\psi_{z1}, \\psi_{z2})$ is the Beta function, and $\\psi_z = (\\psi_{z1}, \\psi_{z2})$ parameterizes the Beta distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Inference in ToT uses **Gibbs sampling** for approximate posterior inference.\n",
    "\n",
    "1. **Conditional Probability**:\n",
    "   The conditional distribution for $z_{di}$ given words and timestamps is:\n",
    "   $$\n",
    "   P(z_{di} | w, t, z_{-di}, \\alpha, \\beta, \\Psi) \\propto (m_{d z_{di}} + \\alpha_{z_{di}} - 1) \\cdot \\frac{n_{z_{di} w_{di}} + \\beta_{w_{di}} - 1}{\\sum_{v=1}^{V} (n_{z_{di} v} + \\beta_v - 1)} \\cdot p(t_{di} | \\psi_{z_{di}})\n",
    "   $$\n",
    "   where $m_{d z_{di}}$ is the number of words in document $d$ assigned to topic $z_{di}$, and $n_{z_{di} w_{di}}$ is the number of words $w_{di}$ assigned to topic $z_{di}$.\n",
    "\n",
    "2. **Beta Distribution Parameters**:\n",
    "   The Beta distribution parameters are estimated via the method of moments:\n",
    "   $$\n",
    "   \\psi_{z1} = t_z \\left( \\frac{t_z (1 - t_z)}{s_z^2} - 1 \\right)\n",
    "   $$\n",
    "   $$\n",
    "   \\psi_{z2} = (1 - t_z) \\left( \\frac{t_z (1 - t_z)}{s_z^2} - 1 \\right)\n",
    "   $$\n",
    "   where $t_z$ and $s_z^2$ are the sample mean and variance of timestamps for topic $z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Strength\n",
    "\n",
    "- ToT captures temporal trends in topic popularity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weakness\n",
    "- Unfortunately, neither Python nor R exists in libraries that reproduce the ToT model as the formula implemented in the paper."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
