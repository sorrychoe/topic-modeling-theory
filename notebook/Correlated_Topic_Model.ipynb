{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlated Topic Model (CTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Author information\n",
    "\n",
    "- **Name:** Jaeseong Choe\n",
    "\n",
    "- **email address:** 21900759@handong.ac.kr\n",
    "\n",
    "- **GitHub:** https://github.com/sorrychoe\n",
    "\n",
    "- **Linkedin:** https://www.linkedin.com/in/jaeseong-choe-048639250/\n",
    "\n",
    "- **Personal Webpage:** https://jaeseongchoe.vercel.app/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Brief background of methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "- Correlated Topic Model (CTM) extends LDA to allow for correlations between topics. \n",
    "\n",
    "- It models the correlations among topics by using a logistic normal distribution for the topic proportions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Situation Before CTM\n",
    "\n",
    "- LDA assumes that topics are independent, which may not be realistic in many cases where topics are correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why CTM Was Introduced\n",
    "\n",
    "- CTM was introduced from the paper *\"A Correlated Topic Model of Science.\"* of Blei, D. M., & Lafferty, J. D. (2007).\n",
    "\n",
    "- CTM extends LDA by modeling correlations among topics using a logistic normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Cases\n",
    "\n",
    "- CTM is beneficial in applications where topics are expected to co-occur or have inherent relationships."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Key concept of methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Concept\n",
    "\n",
    "- CTM uses a logistic normal distribution to model correlations between topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Process\n",
    "CTM uses a logistic normal distribution to capture topic correlations, improving upon LDA's independence assumption. The generative process is as follows:\n",
    "\n",
    "1. **Topic Proportions**:\n",
    "   - Draw topic proportions for each document from a logistic normal distribution:\n",
    "   \n",
    "   $$\n",
    "   \\eta \\sim \\mathcal{N}(\\mu, \\Sigma)\n",
    "   $$\n",
    "   \n",
    "   - Transform the normal variables $\\eta$ into the topic proportions using the following transformation:\n",
    "   \n",
    "   $$\n",
    "   \\theta_i = \\frac{\\exp(\\eta_i)}{\\sum_{j=1}^K \\exp(\\eta_j)}\n",
    "   $$\n",
    "\n",
    "2. **Document Generation**:\n",
    "   - For each word in a document:\n",
    "     - Draw a topic assignment $z_n$ from the multinomial distribution over topics:\n",
    "     \n",
    "     $$\n",
    "     z_n \\sim \\text{Multinomial}(\\theta)\n",
    "     $$\n",
    "     \n",
    "     - Draw a word $w_n$ from the topic-specific word distribution:\n",
    "     \n",
    "     $$\n",
    "     w_n \\sim \\text{Multinomial}(\\beta_{z_n})\n",
    "     $$\n",
    "\n",
    "This model allows for the correlation between topics, unlike LDA, where topic proportions are drawn independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CTM_Graphic](./img/CTM_Graphic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical Representation\n",
    "- **Logistic Normal Distribution**: Topic proportions are drawn from a logistic normal distribution, which is a transformation of a multivariate normal:\n",
    "  \n",
    "  $$\n",
    "  \\eta \\sim \\mathcal{N}(\\mu, \\Sigma)\n",
    "  $$\n",
    "  \n",
    "  The logistic transformation maps the natural parameters $\\eta$ to the simplex, producing the topic proportions $\\theta$.\n",
    "\n",
    "- **Natural Parameterization**: The natural parameterization of a K-dimensional multinomial distribution is:\n",
    "  \n",
    "  $$\n",
    "  p(z | \\eta) = \\exp(\\eta^\\top z - a(\\eta))\n",
    "  $$\n",
    "  \n",
    "  where $a(\\eta) = \\log \\left( \\sum_{i=1}^K \\exp(\\eta_i) \\right)$ is the log normalizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Inference\n",
    "Posterior inference in CTM is challenging due to the non-conjugacy of the logistic normal and multinomial distributions. CTM uses **mean-field variational inference** to approximate the posterior.\n",
    "\n",
    "- **Variational Inference**: The variational distribution is factorized for the latent variables $\\eta$ and $z$:\n",
    "  \n",
    "  $$\n",
    "  q(\\eta, z) = \\prod_{i=1}^K q(\\eta_i | \\lambda_i, \\nu_i^2) \\prod_{n=1}^N q(z_n | \\phi_n)\n",
    "  $$\n",
    "\n",
    "  Here, $\\lambda_i$ and $\\nu_i^2$ are the variational parameters for the Gaussian distribution of $\\eta$, and $\\phi_n$ is the variational parameter for the multinomial distribution of $z_n$.\n",
    "\n",
    "- **Optimization**: The variational parameters are optimized using **coordinate ascent**:\n",
    "  1. Update $\\phi_n$, the variational parameter for $z_n$, as:\n",
    "  \n",
    "     $$\n",
    "     \\phi_n \\propto \\exp(\\lambda + \\log(\\beta_{z_n}))\n",
    "     $$\n",
    "     \n",
    "  2. Update $\\lambda$ and $\\nu^2$, the variational parameters for $\\eta$, using gradient ascent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Strength\n",
    "\n",
    "- CTM captures dependencies between topics, which LDA does not."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before Sample code\n",
    "- Generally, the gensim library is used for topic modeling, but tomotopy was used in this practice.\n",
    "- The reason is that the library is excellent in terms of speed and is characterized by best reproduction of the mathematical formulas mentioned in the paper.\n",
    "- Although it is not a library with many users yet, it is a library that is emerging as an alternative to gensim, so topic modeling was attempted through this library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precautions\n",
    "\n",
    "- If you re-execute the code, there may be a slight difference in the result.\n",
    "\n",
    "- Of course, the difference in the number or content of the topic will not be significant due to the seed number and the learning rate, but the number of the topic changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librarys\n",
    "import numpy as np # for data preprocessing\n",
    "import pandas as pd # for load excel data\n",
    "import pyBigKinds as pbk # for preprocessing bigkinds text data\n",
    "import tomotopy as tp # for topic modeling\n",
    "from pyvis.network import Network # for visualize the CTM result\n",
    "\n",
    "# for ignore the warning message\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctmmodel(df:pd.DataFrame, k:int):\n",
    "    \"\"\"Define CTM model \"\"\"\n",
    "    \n",
    "    words = pbk.keyword_parser(pbk.keyword_list(df))\n",
    "    model = tp.CTModel(min_cf=5, rm_top=10, k=k, seed=42)\n",
    "\n",
    "    for k in range(len(words)):\n",
    "        model.add_doc(words=words[k])\n",
    "\n",
    "    model.train(0)\n",
    "\n",
    "    # Since we have more than ten thousand of documents, \n",
    "    # setting the `num_beta_sample` smaller value will not cause an inaccurate result.\n",
    "    model.num_beta_sample = 5\n",
    "    print('Num docs:{}, Num Vocabs:{}, Total Words:{}'.format(\n",
    "        len(model.docs), len(model.used_vocabs), model.num_words\n",
    "    ))\n",
    "    print('Removed Top words: ', *model.removed_top_words)\n",
    "    \n",
    "    # train the model\n",
    "    model.train(2000, show_progress=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_proper_k(df:pd.DataFrame, start:int, end:int):\n",
    "    \"\"\"find proper k value for hyperparameter tunning\"\"\"\n",
    "\n",
    "    words = pbk.keyword_parser(pbk.keyword_list(df))\n",
    "\n",
    "    for i in range(start,end+1):        \n",
    "        # model setting\n",
    "        mdl=tp.CTModel(tw=tp.TermWeight.IDF, min_cf=5, rm_top=10, k=i, seed=42)\n",
    "        \n",
    "        for k in range(len(words)):\n",
    "            mdl.add_doc(words=words[k])\n",
    "            \n",
    "        # pre-train the model for check the coherence score\n",
    "        mdl.train(100)\n",
    "        \n",
    "        # get the coherence score\n",
    "        coh = tp.coherence.Coherence(mdl, coherence='c_v')\n",
    "        \n",
    "        # coherence average\n",
    "        average_coherence = coh.get_score()\n",
    "        # initial value setup\n",
    "        if i == start:\n",
    "            proper_k = start\n",
    "            tmp = average_coherence\n",
    "        \n",
    "        # get coherence per topic\n",
    "        coherence_per_topic = [coh.get_score(topic_id=k) for k in range(mdl.k)]\n",
    "        \n",
    "        # print it out\n",
    "        print('==== Coherence : k = {} ===='.format(i))\n",
    "        print(\"\\n\")\n",
    "        print('Average: {}'.format(average_coherence))\n",
    "        print(\"\\n\")\n",
    "        print('Per Topic:{}'.format(coherence_per_topic))\n",
    "        print(\"\\n\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # update k\n",
    "        if tmp < average_coherence:\n",
    "            proper_k = i\n",
    "            tmp = average_coherence\n",
    "    return proper_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ctm_network(mdl):\n",
    "    \"\"\"ctm result visualization through Network\"\"\"\n",
    "\n",
    "    g = Network(width=800, height=800, font_color=\"#333\")\n",
    "    correl = mdl.get_correlations().reshape([-1])\n",
    "    correl.sort()\n",
    "    top_tenth = mdl.k * (mdl.k - 1) // 10\n",
    "    top_tenth = correl[-mdl.k - top_tenth]\n",
    "    \n",
    "    for k in range(mdl.k):\n",
    "        label = \"#{}\".format(k)\n",
    "        title= ' '.join(word for word, _ in mdl.get_topic_words(k, top_n=6))\n",
    "        print('Topic', label, title)\n",
    "        g.add_node(k, label=label, title=title, shape='ellipse')\n",
    "        for l, correlation in zip(range(k - 1), mdl.get_correlations(k)):\n",
    "            if correlation < top_tenth: continue\n",
    "            g.add_edge(k, l, value=float(correlation), title='{:.02}'.format(correlation))\n",
    "    \n",
    "    g.barnes_hut(gravity=-1000, spring_length=20)\n",
    "    g.show_buttons()\n",
    "    g.show(\"view/topic_network.html\", notebook=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Coherence : k = 3 ====\n",
      "\n",
      "\n",
      "Average: 0.5469152451958507\n",
      "\n",
      "\n",
      "Per Topic:[0.5734525308012962, 0.5608294982928783, 0.5064637064933777]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==== Coherence : k = 4 ====\n",
      "\n",
      "\n",
      "Average: 0.443054432189092\n",
      "\n",
      "\n",
      "Per Topic:[0.514208522439003, 0.47966777831315993, 0.4169865742325783, 0.36135485377162696]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==== Coherence : k = 5 ====\n",
      "\n",
      "\n",
      "Average: 0.5091650255769491\n",
      "\n",
      "\n",
      "Per Topic:[0.4947906039655209, 0.5389226507395506, 0.5601890429854393, 0.4538996122777462, 0.4980232179164886]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==== Coherence : k = 6 ====\n",
      "\n",
      "\n",
      "Average: 0.5469936619823178\n",
      "\n",
      "\n",
      "Per Topic:[0.6473274737596512, 0.4905784908682108, 0.6215087890625, 0.6285855807363987, 0.4551302820444107, 0.4388313554227352]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==== Coherence : k = 7 ====\n",
      "\n",
      "\n",
      "Average: 0.5035159835991051\n",
      "\n",
      "\n",
      "Per Topic:[0.4621864646673203, 0.5850352458655834, 0.49095904380083083, 0.397606080584228, 0.5844570457935333, 0.50725132599473, 0.4971166784875095]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==== Coherence : k = 8 ====\n",
      "\n",
      "\n",
      "Average: 0.6506026376504451\n",
      "\n",
      "\n",
      "Per Topic:[0.9076479494571685, 0.7992440696805716, 0.6307563237845898, 0.7040342092514038, 0.6188989400863647, 0.5564039524644613, 0.5431265156716109, 0.4447091408073902]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==== Coherence : k = 9 ====\n",
      "\n",
      "\n",
      "Average: 0.5764714834590753\n",
      "\n",
      "\n",
      "Per Topic:[0.6792466819286347, 0.5831801742315292, 0.6142482697963715, 0.6099691778421402, 0.5142368152737617, 0.49980989992618563, 0.6129562392830848, 0.585261982679367, 0.4893341101706028]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==== Coherence : k = 10 ====\n",
      "\n",
      "\n",
      "Average: 0.6652460142644122\n",
      "\n",
      "\n",
      "Per Topic:[0.8363345801830292, 0.7881951034069061, 0.7035184298176318, 0.6689259767532348, 0.5422614447772502, 0.6084149032831192, 0.7031474888324738, 0.6494134187698364, 0.6209076151251793, 0.5313411816954613]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data load\n",
    "# The data is related to Handong University, \n",
    "# which was reported in major Korean daily newspapers from January 1995 to September 2024.\n",
    "df = pd.read_excel(\"data/NewsResult_19950101-20240930.xlsx\", engine=\"openpyxl\")\n",
    "\n",
    "# proper k value\n",
    "proper_k = find_proper_k(df, 3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num docs:8051, Num Vocabs:27099, Total Words:1657565\n",
      "Removed Top words:  미국 대학 북한 교수 한동대 한국 대통령 정부 교육 중국\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|███████████| 2000/2000 [01:55<00:00, 17.34it/s, LLPW: -6.978222]\n"
     ]
    }
   ],
   "source": [
    "# Model setting with K\n",
    "mdl = ctmmodel(df, proper_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Basic Info>\n",
      "| CTModel (current version: 0.12.7)\n",
      "| 8051 docs, 1657565 words\n",
      "| Total Vocabs: 128176, Used Vocabs: 27099\n",
      "| Entropy of words: 8.65140\n",
      "| Entropy of term-weighted words: 8.65140\n",
      "| Removed Vocabs: 미국 대학 북한 교수 한동대 한국 대통령 정부 교육 중국\n",
      "|\n",
      "<Training Info>\n",
      "| Iterations: 2000, Burn-in steps: 0\n",
      "| Optimization Interval: 2\n",
      "| Log-likelihood per word: -6.98059\n",
      "|\n",
      "<Initial Parameters>\n",
      "| tw: TermWeight.ONE\n",
      "| min_cf: 5 (minimum collection frequency of words)\n",
      "| min_df: 0 (minimum document frequency of words)\n",
      "| rm_top: 10 (the number of top words to be removed)\n",
      "| k: 10 (the number of topics between 1 ~ 32767)\n",
      "| smoothing_alpha: [0.1] (small smoothing value for preventing topic counts to be zero, given as a single `float` in case of symmetric and as a list with length `k` of `float` in case of asymmetric.)\n",
      "| eta: 0.01 (hyperparameter of Dirichlet distribution for topic-word)\n",
      "| seed: 42 (random seed)\n",
      "| trained in version 0.12.7\n",
      "|\n",
      "<Parameters>\n",
      "| prior_mean (Prior mean of Logit-normal for the per-document topic distributions)\n",
      "|  [-5.7438111e+00 -3.6367950e+00 -4.5785894e+00 -1.7569729e+00\n",
      "|   -2.4756813e+00 -3.9365087e+00 -5.3165603e-01 -2.2017527e-01\n",
      "|   -3.2525226e-02 -4.4823871e-03]\n",
      "| prior_cov (Prior covariance of Logit-normal for the per-document topic distributions)\n",
      "|  [[ 1.79175301e+01  8.35183907e+00 -8.11565971e+00  3.77883172e+00\n",
      "|    -7.70613337e+00 -6.24639511e+00  1.36795008e+00 -7.66347945e-01\n",
      "|     2.62349192e-02 -2.19664481e-02]\n",
      "|   [ 8.35183907e+00  1.82878323e+01 -7.25439072e+00  5.50075293e+00\n",
      "|    -5.68564749e+00 -2.96797323e+00  2.04857969e+00 -3.58583868e-01\n",
      "|     4.28696945e-02 -1.64682698e-02]\n",
      "|   [-8.11565971e+00 -7.25439072e+00  1.94564571e+01 -7.61369526e-01\n",
      "|     6.40080118e+00  1.31360006e+00 -1.80009735e+00  4.20247108e-01\n",
      "|     5.42100929e-02  6.27727881e-02]\n",
      "|   [ 3.77883172e+00  5.50075293e+00 -7.61369526e-01  1.10482159e+01\n",
      "|    -2.48933887e+00 -3.98257709e+00  4.55319613e-01 -1.89601257e-01\n",
      "|     1.21684894e-01  2.25869138e-02]\n",
      "|   [-7.70613337e+00 -5.68564749e+00  6.40080118e+00 -2.48933887e+00\n",
      "|     1.32968540e+01  3.46913624e+00 -1.01131666e+00  5.71535587e-01\n",
      "|     6.11216808e-03  2.76976433e-02]\n",
      "|   [-6.24639511e+00 -2.96797323e+00  1.31360006e+00 -3.98257709e+00\n",
      "|     3.46913624e+00  1.82399807e+01  7.38541245e-01  9.34557557e-01\n",
      "|     2.09469050e-02  2.01734668e-03]\n",
      "|   [ 1.36795008e+00  2.04857969e+00 -1.80009735e+00  4.55319613e-01\n",
      "|    -1.01131666e+00  7.38541245e-01  1.88558459e+00  5.57825603e-02\n",
      "|     1.43685862e-02 -6.61211787e-03]\n",
      "|   [-7.66347945e-01 -3.58583868e-01  4.20247108e-01 -1.89601257e-01\n",
      "|     5.71535587e-01  9.34557557e-01  5.57825603e-02  6.64917648e-01\n",
      "|     2.96144690e-02  4.34689457e-03]\n",
      "|   [ 2.62349192e-02  4.28696945e-02  5.42100929e-02  1.21684894e-01\n",
      "|     6.11216808e-03  2.09469050e-02  1.43685862e-02  2.96144690e-02\n",
      "|     3.64257097e-02  1.43897289e-03]\n",
      "|   [-2.19664481e-02 -1.64682698e-02  6.27727881e-02  2.25869138e-02\n",
      "|     2.76976433e-02  2.01734668e-03 -6.61211787e-03  4.34689457e-03\n",
      "|     1.43897289e-03  1.74483459e-03]]\n",
      "| eta (Dirichlet prior on the per-topic word distribution)\n",
      "|  0.01\n",
      "|\n",
      "<Topics>\n",
      "| #0 (144428) : 트럼프 협상 외교 회담 남북\n",
      "| #1 (154823) : 일본 위원장 장관 입장 정치\n",
      "| #2 (141447) : 포항 전형 모집 지원 지진\n",
      "| #3 (171935) : 전략 정책 상황 결정 국가\n",
      "| #4 (156852) : 학생 총장 학교 학생들 서울대\n",
      "| #5 (148885) : 교회 목사 하나님 기독교 사랑\n",
      "| #6 (178204) : 대표 생각 국민 의미 통일\n",
      "| #7 (183526) : 사회 세계 참여 분야 활동\n",
      "| #8 (188270) : 지역 협력 국제 운영 예정\n",
      "| #9 (189195) : 서울 평가 지원 진행 시작\n",
      "|\n",
      "\n",
      "Topic #0 트럼프 협상 외교 회담 남북 한반도\n",
      "Topic #1 일본 위원장 장관 입장 정치 가능성\n",
      "Topic #2 포항 전형 모집 지원 지진 포항시\n",
      "Topic #3 전략 정책 상황 결정 국가 가능\n",
      "Topic #4 학생 총장 학교 학생들 서울대 연세대\n",
      "Topic #5 교회 목사 하나님 기독교 사랑 기도\n",
      "Topic #6 대표 생각 국민 의미 통일 인권\n",
      "Topic #7 사회 세계 참여 분야 활동 회장\n",
      "Topic #8 지역 협력 국제 운영 예정 프로그램\n",
      "Topic #9 서울 평가 지원 진행 시작 사업\n",
      "view/topic_network.html\n"
     ]
    }
   ],
   "source": [
    "# get summary\n",
    "mdl.summary()\n",
    "\n",
    "# save model\n",
    "get_ctm_network(mdl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The result of Topic Modeling \n",
    "\n",
    "- Topic #0: Topic related to North Korea and Inter-Korean Relations\n",
    "\n",
    "- Topic #1: Topic related to International Relations and Global Affairs\n",
    "\n",
    "- Topic #2: Topic related to the university entrance examination system\n",
    "\n",
    "- Topic #3: Topic related to the Professors in Politics and Government Affairs\n",
    "\n",
    "- Topic #4: Topic related to the Promotion of Handong University\n",
    "\n",
    "- Topic #5: Topic related to Religious Activities and Christian Identity of Handong University\n",
    "\n",
    "- Topic #6: Topic related to the desire of members of Handong University for unification\n",
    "\n",
    "- Topic #7: Topic related to the social activities of students and professors of Handong University\n",
    "\n",
    "- Topic #8: Topic related to Handong University's business collaborating with the local community\n",
    "\n",
    "- Topic #9: Topic related to Glocal University 30 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why are the results of LDA and CTM different?\n",
    "\n",
    "- LDA use the Dirichlet Distributions for sampling The document-topic and topic-word distributions.\n",
    "\n",
    "- CTM use the Multivariate Normal Distribution for sampling the document-topic distribution for capturing topic correlations.\n",
    "\n",
    "- Unlike LDA, CTM allows for the modeling of dependencies between topics, meaning that the appearance of one topic might increase the likelihood of other correlated topics appearing within the same document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "    <head>\n",
       "        <meta charset=\"utf-8\">\n",
       "        \n",
       "            <script src=\"lib/bindings/utils.js\"></script>\n",
       "            <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css\" integrity=\"sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\" />\n",
       "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js\" integrity=\"sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></script>\n",
       "            \n",
       "        \n",
       "<center>\n",
       "<h1></h1>\n",
       "</center>\n",
       "\n",
       "<!-- <link rel=\"stylesheet\" href=\"../node_modules/vis/dist/vis.min.css\" type=\"text/css\" />\n",
       "<script type=\"text/javascript\" src=\"../node_modules/vis/dist/vis.js\"> </script>-->\n",
       "        <link\n",
       "          href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css\"\n",
       "          rel=\"stylesheet\"\n",
       "          integrity=\"sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6\"\n",
       "          crossorigin=\"anonymous\"\n",
       "        />\n",
       "        <script\n",
       "          src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js\"\n",
       "          integrity=\"sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf\"\n",
       "          crossorigin=\"anonymous\"\n",
       "        ></script>\n",
       "\n",
       "\n",
       "        <center>\n",
       "          <h1></h1>\n",
       "        </center>\n",
       "        <style type=\"text/css\">\n",
       "\n",
       "             #mynetwork {\n",
       "                 width: 800;\n",
       "                 height: 800;\n",
       "                 background-color: #ffffff;\n",
       "                 border: 1px solid lightgray;\n",
       "                 position: relative;\n",
       "                 float: left;\n",
       "             }\n",
       "\n",
       "             \n",
       "\n",
       "             \n",
       "             #config {\n",
       "                 float: left;\n",
       "                 width: 400px;\n",
       "                 height: 600px;\n",
       "             }\n",
       "             \n",
       "\n",
       "             \n",
       "        </style>\n",
       "    </head>\n",
       "\n",
       "\n",
       "    <body>\n",
       "        <div class=\"card\" style=\"width: 100%\">\n",
       "            \n",
       "            \n",
       "            <div id=\"mynetwork\" class=\"card-body\"></div>\n",
       "        </div>\n",
       "\n",
       "        \n",
       "        \n",
       "            <div id=\"config\"></div>\n",
       "        \n",
       "\n",
       "        <script type=\"text/javascript\">\n",
       "\n",
       "              // initialize global variables.\n",
       "              var edges;\n",
       "              var nodes;\n",
       "              var allNodes;\n",
       "              var allEdges;\n",
       "              var nodeColors;\n",
       "              var originalNodes;\n",
       "              var network;\n",
       "              var container;\n",
       "              var options, data;\n",
       "              var filter = {\n",
       "                  item : '',\n",
       "                  property : '',\n",
       "                  value : []\n",
       "              };\n",
       "\n",
       "              \n",
       "\n",
       "              \n",
       "\n",
       "              // This method is responsible for drawing the graph, returns the drawn network\n",
       "              function drawGraph() {\n",
       "                  var container = document.getElementById('mynetwork');\n",
       "\n",
       "                  \n",
       "\n",
       "                  // parsing and collecting nodes and edges from the python\n",
       "                  nodes = new vis.DataSet([{\"color\": \"#97c2fc\", \"font\": {\"color\": \"#333\"}, \"id\": 0, \"label\": \"#0\", \"shape\": \"ellipse\", \"title\": \"\\ud2b8\\ub7fc\\ud504 \\ud611\\uc0c1 \\uc678\\uad50 \\ud68c\\ub2f4 \\ub0a8\\ubd81 \\ud55c\\ubc18\\ub3c4\"}, {\"color\": \"#97c2fc\", \"font\": {\"color\": \"#333\"}, \"id\": 1, \"label\": \"#1\", \"shape\": \"ellipse\", \"title\": \"\\uc77c\\ubcf8 \\uc704\\uc6d0\\uc7a5 \\uc7a5\\uad00 \\uc785\\uc7a5 \\uc815\\uce58 \\uac00\\ub2a5\\uc131\"}, {\"color\": \"#97c2fc\", \"font\": {\"color\": \"#333\"}, \"id\": 2, \"label\": \"#2\", \"shape\": \"ellipse\", \"title\": \"\\ud3ec\\ud56d \\uc804\\ud615 \\ubaa8\\uc9d1 \\uc9c0\\uc6d0 \\uc9c0\\uc9c4 \\ud3ec\\ud56d\\uc2dc\"}, {\"color\": \"#97c2fc\", \"font\": {\"color\": \"#333\"}, \"id\": 3, \"label\": \"#3\", \"shape\": \"ellipse\", \"title\": \"\\uc804\\ub7b5 \\uc815\\ucc45 \\uc0c1\\ud669 \\uacb0\\uc815 \\uad6d\\uac00 \\uac00\\ub2a5\"}, {\"color\": \"#97c2fc\", \"font\": {\"color\": \"#333\"}, \"id\": 4, \"label\": \"#4\", \"shape\": \"ellipse\", \"title\": \"\\ud559\\uc0dd \\ucd1d\\uc7a5 \\ud559\\uad50 \\ud559\\uc0dd\\ub4e4 \\uc11c\\uc6b8\\ub300 \\uc5f0\\uc138\\ub300\"}, {\"color\": \"#97c2fc\", \"font\": {\"color\": \"#333\"}, \"id\": 5, \"label\": \"#5\", \"shape\": \"ellipse\", \"title\": \"\\uad50\\ud68c \\ubaa9\\uc0ac \\ud558\\ub098\\ub2d8 \\uae30\\ub3c5\\uad50 \\uc0ac\\ub791 \\uae30\\ub3c4\"}, {\"color\": \"#97c2fc\", \"font\": {\"color\": \"#333\"}, \"id\": 6, \"label\": \"#6\", \"shape\": \"ellipse\", \"title\": \"\\ub300\\ud45c \\uc0dd\\uac01 \\uad6d\\ubbfc \\uc758\\ubbf8 \\ud1b5\\uc77c \\uc778\\uad8c\"}, {\"color\": \"#97c2fc\", \"font\": {\"color\": \"#333\"}, \"id\": 7, \"label\": \"#7\", \"shape\": \"ellipse\", \"title\": \"\\uc0ac\\ud68c \\uc138\\uacc4 \\ucc38\\uc5ec \\ubd84\\uc57c \\ud65c\\ub3d9 \\ud68c\\uc7a5\"}, {\"color\": \"#97c2fc\", \"font\": {\"color\": \"#333\"}, \"id\": 8, \"label\": \"#8\", \"shape\": \"ellipse\", \"title\": \"\\uc9c0\\uc5ed \\ud611\\ub825 \\uad6d\\uc81c \\uc6b4\\uc601 \\uc608\\uc815 \\ud504\\ub85c\\uadf8\\ub7a8\"}, {\"color\": \"#97c2fc\", \"font\": {\"color\": \"#333\"}, \"id\": 9, \"label\": \"#9\", \"shape\": \"ellipse\", \"title\": \"\\uc11c\\uc6b8 \\ud3c9\\uac00 \\uc9c0\\uc6d0 \\uc9c4\\ud589 \\uc2dc\\uc791 \\uc0ac\\uc5c5\"}]);\n",
       "                  edges = new vis.DataSet([{\"from\": 3, \"title\": \"0.39\", \"to\": 1, \"value\": 0.38698574900627136}, {\"from\": 4, \"title\": \"0.4\", \"to\": 2, \"value\": 0.39794954657554626}, {\"from\": 6, \"title\": \"0.35\", \"to\": 1, \"value\": 0.3488580584526062}, {\"from\": 9, \"title\": \"0.34\", \"to\": 2, \"value\": 0.3406923711299896}]);\n",
       "\n",
       "                  nodeColors = {};\n",
       "                  allNodes = nodes.get({ returnType: \"Object\" });\n",
       "                  for (nodeId in allNodes) {\n",
       "                    nodeColors[nodeId] = allNodes[nodeId].color;\n",
       "                  }\n",
       "                  allEdges = edges.get({ returnType: \"Object\" });\n",
       "                  // adding nodes and edges to the graph\n",
       "                  data = {nodes: nodes, edges: edges};\n",
       "\n",
       "                  var options = {\n",
       "    \"configure\": {\n",
       "        \"enabled\": true\n",
       "    },\n",
       "    \"edges\": {\n",
       "        \"color\": {\n",
       "            \"inherit\": true\n",
       "        },\n",
       "        \"smooth\": {\n",
       "            \"enabled\": true,\n",
       "            \"type\": \"dynamic\"\n",
       "        }\n",
       "    },\n",
       "    \"interaction\": {\n",
       "        \"dragNodes\": true,\n",
       "        \"hideEdgesOnDrag\": false,\n",
       "        \"hideNodesOnDrag\": false\n",
       "    },\n",
       "    \"physics\": {\n",
       "        \"barnesHut\": {\n",
       "            \"avoidOverlap\": 0,\n",
       "            \"centralGravity\": 0.3,\n",
       "            \"damping\": 0.09,\n",
       "            \"gravitationalConstant\": -1000,\n",
       "            \"springConstant\": 0.001,\n",
       "            \"springLength\": 20\n",
       "        },\n",
       "        \"enabled\": true,\n",
       "        \"stabilization\": {\n",
       "            \"enabled\": true,\n",
       "            \"fit\": true,\n",
       "            \"iterations\": 1000,\n",
       "            \"onlyDynamicEdges\": false,\n",
       "            \"updateInterval\": 50\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "                  \n",
       "\n",
       "\n",
       "                  \n",
       "                  // if this network requires displaying the configure window,\n",
       "                  // put it in its div\n",
       "                  options.configure[\"container\"] = document.getElementById(\"config\");\n",
       "                  \n",
       "\n",
       "                  network = new vis.Network(container, data, options);\n",
       "\n",
       "                  \n",
       "\n",
       "                  \n",
       "\n",
       "                  \n",
       "\n",
       "\n",
       "                  \n",
       "\n",
       "                  return network;\n",
       "\n",
       "              }\n",
       "              drawGraph();\n",
       "        </script>\n",
       "    </body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(filename=\"view/topic_network.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result interpretation\n",
    "\n",
    "- Unlike traditional models, CTM is capable of topic modeling considering correlation coefficients between topics.\n",
    "\n",
    "- In this result, Topic 1 and 3 are showing a strong positive correlation. This is because it is a topic that contains the  international relations content.\n",
    "\n",
    "- Futhermore, Topic 2 and 4 are also showing a strong positive correlation. This is because it includes words related to the university entrance.\n",
    "\n",
    "- As you can see, Topic 2 and 9, Topic 1 and 6 has a positive correlation. This is because some words In their topic tend to be used together within a specific topic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
